# Quantum Transfer Learning (QTL) – Reusing PQC Features

## What This Project Does
This repository shows how to reuse a parameterized quantum circuit (PQC) trained on one "source" classification task for a related "target" task. A small classical classifier head is placed on top of the PQC outputs. We compare two strategies:

1. **Frozen PQC + Trainable Head:** keep the PQC weights fixed and train only the head on the target task.
2. **Fine-tuned PQC + Head:** train both the PQC and the head on the target task.

## Why Quantum Transfer Learning Is Interesting
- PQCs can learn expressive quantum feature maps that are expensive to relearn from scratch.
- Reusing a trained PQC can reduce data needs and speed up training on related tasks.
- This mirrors classical transfer learning (for example, taking ImageNet features from a CNN backbone).

## Why SVG Instead of PNG
GitHub's CODEX interface cannot preview binary image files like PNG or JPG and often shows "Binary files are not supported" in pull request views. To avoid this, all visualizations in this repository are saved as lightweight SVG (vector) images. SVGs are text-based, easy to diff, and render cleanly inside GitHub and CODEX.

## How It Works (Plain English)
- Train a small PQC on a simple 2D source dataset.
- Freeze the PQC parameters so they no longer change.
- On the target dataset, feed inputs through the frozen PQC to get feature vectors.
- Train a tiny linear classifier head on those features.
- Compare this frozen approach against full fine-tuning where the PQC is also updated.

## Repository Structure
- `app/` – datasets, PQC model, feature extractor, classifier head, transfer pipelines, plotting, CLI entrypoint.
- `notebooks/` – beginner-friendly end-to-end demo notebook.
- `examples/` – SVG-only plots generated by the demo.
- `tests/` – lightweight pytest checks to ensure the pipeline runs.

## How to Run
```bash
pip install -r requirements.txt
python app/main.py
```

Notebook:

```bash
jupyter notebook notebooks/qtl_demo.ipynb
```

## What You Should See
- Training curves for frozen vs fine-tuned PQC on the target task.
- Feature-space visualization of source vs target embeddings.
- Accuracy comparison bar chart.

## Future Work
- Deeper PQCs and larger datasets.
- Hardware experiments on NISQ devices.
- Mixed quantum–classical transfer learning pipelines.
